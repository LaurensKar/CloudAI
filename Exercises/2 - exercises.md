# Exercises part 2
## Data science, data exploration

Download the Titanic dataset from [Kaggle](https://www.kaggle.com/datasets/vinicius150987/titanic3).

Open Sagemaker using free credits or run locally in a virtual environment.

__If you haven’t started doing this yet, start it now: every project you do goes in its own personal virtual environment. Never in the main environment unless it uses no libraries. Git is useful but optional, virtual environments are not (optional, as it is very useful).__

Quick reminder from data science course:

```Python
python -m venv venv
./venv/Scripts/activate
```

Once you’ve loaded your data, go full data scientist on it:
1.	Perform data preprocessing, which includes handling missing values, converting categorical features to numerical, and feature scaling.
2.	Use feature selection techniques to select the most important features for the models. Try using correlation analysis or feature importance from models like the decision tree or random forest.
3.	Use cross-validation techniques such as k-fold cross-validation to evaluate the models' performance and avoid overfitting.
4.	Use ensemble methods like stacking or blending to combine the predictions from multiple models and improve the overall performance.
5.	Use hyperparameter optimization techniques such as Bayesian optimization or genetic algorithms to find the optimal hyperparameters for the models.
6.	Use techniques like data augmentation or synthetic minority oversampling technique (SMOTE) to handle class imbalance in the target variable.
7.	Use different evaluation metrics like ROC AUC or average precision score to evaluate the models' performance, especially when dealing with imbalanced datasets.
8.	Visualize the models' performance using metrics like confusion matrix, ROC curve, or precision-recall curve to better understand the models' strengths and weaknesses.
9.	Interpret the models' results using techniques like feature importance, partial dependence plots, or SHAP values to understand the factors that contribute to the models' predictions.
10.	Use techniques like pipeline or GridSearchCV to create reproducible and efficient workflows for building and evaluating the models.

These exercises focus more on the data science aspects of supervised machine learning, including data preprocessing, feature selection, cross-validation, hyperparameter optimization, and model interpretation. These are crucial skills for data scientists working with supervised machine learning problems, and mastering them will help you build better models and make better decisions


